{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P&D ISSP - Base notebook\n",
    "@Students: You are free to edit anything you want."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import package.general as genfcns\n",
    "import package.gui_utils as guifcns\n",
    "matplotlib.style.use('default')  # <-- for notebooks: white figures background\n",
    "\n",
    "# Root path (path to where you are storing this very notebook)\n",
    "ROOTPATH = 'F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main'  #  /!/  Adapt this to your system  /!/ \n",
    "pathToSoundFiles = f'{ROOTPATH}/sound_files/'\n",
    "\n",
    "# Parameters (examples)\n",
    "speechfilenames = [\n",
    "    pathToSoundFiles + 'speech1.wav',\n",
    "    pathToSoundFiles + 'speech2.wav'\n",
    "]\n",
    "noisefilenames = [\n",
    "    pathToSoundFiles + 'Babble_noise1.wav'\n",
    "]\n",
    "signalDuration = 10     # [s]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build acoustic scenario and generate RIRs using GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch GUI\n",
    "guifcns.RIRg_GUI(\n",
    "    exportFolder=f'{os.getcwd()}/rirs',\n",
    "    outputRIRplot=False,\n",
    "    distBwMics=10,  # [cm]\n",
    "    fs=44100,\n",
    "    t60=0,\n",
    "    theme='SystemDefault',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIRs selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Select RIRs to be used\n",
    "# rirFile = 'rirs/'  # use this to input a specific set of RIRs (full path to .pkl.gz file)\n",
    "rirFile = genfcns.select_latest_rir(path='./rirs/')  # use this to select the lastly generated RIRs\n",
    "# Load from Pickle archive\n",
    "acousticScenario = guifcns.load_rirs(path=rirFile)\n",
    "# >>> NB: the RIRs can be accessed as acousticScenario.RIRsAudio /or/ RIRsNoise\n",
    "acousticScenario.plot_asc()  # show the acoustic scenario as a pl\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(acousticScenario.RIRsAudio[0:5000,0,0])\n",
    "\n",
    "# plt.figure()\n",
    "# plt.figure(figsize=(6, 3))\n",
    "# plt.plot(acousticScenario.RIRsNoise[:,0,0])\n",
    "print(acousticScenario.RIRsAudio.shape)\n",
    "# print(acousticScenario)\n",
    "\n",
    "# print(acousticScenario.RIRsAudio)\n",
    "# print(acousticScenario.RIRsNoise.shape)\n",
    "# print(acousticScenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "import scipy\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import scipy.signal as signal\n",
    "import sounddevice as sd\n",
    "\n",
    "def create_micsigs(audio_name1, audio_name2, noise_name, acousticScenario):\n",
    "    num_micro = acousticScenario.RIRsAudio.shape[1]   # number of microphones\n",
    "    num_audio = acousticScenario.RIRsAudio.shape[2]   # number of audio sources\n",
    "    if acousticScenario.RIRsNoise is None:\n",
    "        num_noise = 0   # number of noise sources\n",
    "    else:\n",
    "        num_noise = acousticScenario.RIRsNoise.shape[2]   # number of noise sources\n",
    "        RIR_noise1 = acousticScenario.RIRsNoise.squeeze(axis=2)  \n",
    "      \n",
    "    fs = acousticScenario.fs    # unit: Hz\n",
    "    T_ds = int(10*fs)  # unit: s\n",
    "\n",
    "    if num_audio == 2:\n",
    "        RIR_audio1, RIR_audio2 = np.dsplit(acousticScenario.RIRsAudio, 2)\n",
    "        RIR_audio1 = RIR_audio1.squeeze(axis=2)\n",
    "        RIR_audio2 = RIR_audio2.squeeze(axis=2)\n",
    "    else:\n",
    "        RIR_audio1 = acousticScenario.RIRsAudio.squeeze(axis=2)\n",
    "    \n",
    "    speech1, sr_speech1 = sf.read(audio_name1)\n",
    "    speech2, sr_speech2 = sf.read(audio_name2)\n",
    "    noise1, sr_noise1 = sf.read(noise_name)\n",
    "\n",
    "    num_samples_speech1 = int(len(speech1) * fs / sr_speech1)\n",
    "    num_samples_speech2 = int(len(speech2) * fs / sr_speech2)\n",
    "    num_samples_noise = int(len(noise1) * fs / sr_noise1)\n",
    "    speech1 = signal.resample(speech1, num_samples_speech1)\n",
    "    speech2 = signal.resample(speech2, num_samples_speech2)\n",
    "    noise1 = signal.resample(noise1, num_samples_noise)\n",
    "\n",
    "    speech1 = speech1[0:T_ds]\n",
    "    speech2 = speech2[0:T_ds]\n",
    "    noise1 = noise1[0:T_ds]\n",
    "\n",
    "    mic1 = []\n",
    "    mic2 = []\n",
    "\n",
    "    for i in range(num_micro):\n",
    "        rec_signal1_tmp = scipy.signal.fftconvolve(speech1, RIR_audio1[:,i])\n",
    "        if num_audio == 2:\n",
    "            rec_signal2_tmp = scipy.signal.fftconvolve(speech2, RIR_audio2[:,i])\n",
    "        else:\n",
    "            rec_signal2_tmp = np.zeros(rec_signal1_tmp.shape)\n",
    "\n",
    "        if acousticScenario.RIRsNoise is not None:\n",
    "            rec_noise_tmp = scipy.signal.fftconvolve(noise1, RIR_noise1[:,i])  \n",
    "            rec_signal1_tmp = rec_signal1_tmp + rec_noise_tmp\n",
    "\n",
    "        mic1.append(rec_signal1_tmp)\n",
    "        mic2.append(rec_signal2_tmp)\n",
    "\n",
    "    mic1 = np.array(mic1)\n",
    "    mic2 = np.array(mic2)\n",
    "\n",
    "    mic = mic1 + mic2    \n",
    "    mic = mic.T\n",
    "\n",
    "    return mic[0:T_ds,:], speech1, speech2, noise1, fs\n",
    "\n",
    "mic, speech1, speech2, noise1, fs = create_micsigs('F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\speech1.wav', 'F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\speech2.wav',\"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\Babble_noise1.wav\", acousticScenario)\n",
    "\n",
    "# sd.play(speech1[0:fs*1], fs)\n",
    "sd.play(mic[:,0], fs)\n",
    "\n",
    "print(mic.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(mic[:,0])\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(mic[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "\n",
    "def TDOA_corr(audio1_name, audio2_name, noise_name, acousticScenario):\n",
    "  rir1 = acousticScenario.RIRsAudio[:,0,0]\n",
    "  rir2 = acousticScenario.RIRsAudio[:,1,0]\n",
    "\n",
    "  direct_path_idx1 = np.argmax(np.abs(rir1))\n",
    "  direct_path_idx2 = np.argmax(np.abs(rir2))\n",
    "\n",
    "  ground_truth_TDOA = (direct_path_idx1 - direct_path_idx2) / acousticScenario.fs\n",
    "  print(f\"Ground truth TDOA: {ground_truth_TDOA:.6f} seconds\")\n",
    "\n",
    "  mic_signals, _, _, _, _ = create_micsigs(audio1_name, audio2_name, noise_name, acousticScenario)\n",
    "\n",
    "  mic1 = mic_signals[:, 0] # Signal of the first mic\n",
    "  mic2 = mic_signals[:, 1] # Signal of the second mic\n",
    "\n",
    "  cross_corr = signal.correlate(mic1, mic2, mode=\"full\")\n",
    "  lags = signal.correlation_lags(len(mic1), len(mic2), mode=\"full\")\n",
    "\n",
    "  estimated_TDOA = lags[np.argmax(cross_corr)] / acousticScenario.fs\n",
    "  print(f\"Estimated TDOA: {estimated_TDOA:.6f} seconds\")\n",
    "\n",
    "  plt.figure(figsize=(8, 4))\n",
    "  plt.plot(lags / acousticScenario.fs, cross_corr, label=\"Crosscorrelation\")\n",
    "  plt.stem([ground_truth_TDOA], [np.max(cross_corr)], linefmt=\"r-\", markerfmt=\"ro\", basefmt=\"r-\", label=\"Groundtruth\")\n",
    "  plt.stem([estimated_TDOA], [np.max(cross_corr)], linefmt=\"g-\", markerfmt=\"go\", basefmt=\"g-\", label=\"Estimated value\")\n",
    "\n",
    "  plt.xlabel(\"Time difference (seconden)\")\n",
    "  plt.ylabel(\"Crosscorrelation amplitude\")\n",
    "  plt.legend()\n",
    "  plt.title(\"TDOA estimate via crosscorrelation\")\n",
    "  plt.xlim(-0.01, 0.01)\n",
    "  plt.grid()\n",
    "  plt.show()\n",
    "\n",
    "  # Step 5: Print de fout tussen de schatting en de grondwaarheid\n",
    "  error = np.abs(estimated_TDOA - ground_truth_TDOA)\n",
    "  print(f\"TDOA estimation error: {error:.6f} seconds\")\n",
    "\n",
    "TDOA_corr('F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\whitenoise_signal_1.wav', 'F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\whitenoise_signal_2.wav',\"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\Babble_noise1.wav\", acousticScenario)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4\n",
    "def DOA_corr(audio1_name, audio2_name, noise_name, acousticScenario):\n",
    "  mic_signals, _, _, _, _ = create_micsigs(audio1_name, audio2_name, noise_name, acousticScenario)\n",
    "\n",
    "  mic1 = mic_signals[:,0] # First mic signal\n",
    "  mic2 = mic_signals[:,1] # Second mic signal\n",
    "\n",
    "  cross_corr = signal.correlate(mic1, mic2, mode=\"full\")\n",
    "  lags = signal.correlation_lags(len(mic1), len(mic2), mode=\"full\")\n",
    "\n",
    "  cross_corr /= np.max(np.abs(cross_corr))\n",
    "  peaks, properties = signal.find_peaks(cross_corr, height=0.2) # Peaks above 50% of max\n",
    "\n",
    "  if len(peaks) < 2:\n",
    "    raise ValueError(\"Less than 2 peaks found. Cannot estimate exactly 2 DOAs.\")\n",
    "  \n",
    "  peak_indices = np.argsort(properties[\"peak_heights\"])[-2:] # Get indices of top 2 peaks\n",
    "  selected_peaks = peaks[peak_indices]\n",
    "\n",
    "  TDOAestAll = []\n",
    "\n",
    "  for peak in selected_peaks:\n",
    "    estimated_TDOA = lags[peak] / acousticScenario.fs\n",
    "    TDOAestAll.append(estimated_TDOA)\n",
    "\n",
    "  print(f\"First estimated TDOA: {TDOAestAll[0]:.6f} seconds\")\n",
    "  print(f\"Second estimated TDOA: {TDOAestAll[1]:.6f} seconds\")\n",
    "\n",
    "  c = 340 # Speed of sound in air (m/s)\n",
    "  mic_distance = acousticScenario.distBwMics\n",
    "  TDOAestAll = np.array(TDOAestAll)\n",
    "  cos_theta = (TDOAestAll * c) / mic_distance # estimated cosine of the angle\n",
    "  cos_theta = np.clip(cos_theta, -1, 1)\n",
    "  DOA_estimate = np.arccos(cos_theta) * (180 / np.pi) # Angle in degrees\n",
    "\n",
    "  print(f\"estimated DOA: {DOA_estimate[0]:.2f} degrees\")\n",
    "  print(f\"estimated DOA: {DOA_estimate[1]:.2f} degrees\")\n",
    "  \n",
    "  plt.figure(figsize=(8, 4))\n",
    "  plt.plot(lags / fs, cross_corr, label=\"cross correlation\")\n",
    "  plt.axvline(x=estimated_TDOA, color='g', linestyle=\"--\", label=f\"TDOA: {estimated_TDOA:.6f}s\")\n",
    "\n",
    "  plt.xlabel(\"Time difference (seconds)\")\n",
    "  plt.ylabel(\"Cross correlation amplitude\")\n",
    "  plt.legend()\n",
    "  plt.xlim(-0.01,0.01)\n",
    "  plt.title(\"TDOA and DOA estimation via crosscorrelation\")\n",
    "  plt.grid()\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "  DOAestAll = DOA_estimate\n",
    "  DOAestAll = np.array(DOAestAll)\n",
    "  return DOAestAll\n",
    "\n",
    "DOAestALL = DOA_corr(\"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\whitenoise_signal_1.wav\", \"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\whitenoise_signal_2.wav\", \"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\Babble_noise1.wav\", acousticScenario)\n",
    "print(DOAestALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "def TDOA_corr_2(audio1_name, audio2_name, noise_name, acousticScenario, mic):\n",
    " first_source = 0\n",
    " second_source = 1\n",
    " rir1_1 = acousticScenario.RIRsAudio[:,first_source,0]\n",
    " rir2_1 = acousticScenario.RIRsAudio[:,second_source,0]\n",
    "\n",
    " direct_path_idx1_1 = np.argmax(np.abs(rir1_1))\n",
    " direct_path_idx2_1 = np.argmax(np.abs(rir2_1))\n",
    "\n",
    " ground_truth_TDOA_1 = (direct_path_idx1_1 - direct_path_idx2_1) / acousticScenario.fs\n",
    "\n",
    " print(f\"Ground truth TDOA of source 1: {ground_truth_TDOA_1:.6f} seconds\")\n",
    "\n",
    " rir1_2 = acousticScenario.RIRsAudio[:,first_source,1]\n",
    " rir2_2 = acousticScenario.RIRsAudio[:,second_source,1]\n",
    "\n",
    " direct_path_idx1_2 = np.argmax(np.abs(rir1_2))\n",
    " direct_path_idx2_2 = np.argmax(np.abs(rir2_2))\n",
    "\n",
    " ground_truth_TDOA_2 = (direct_path_idx1_2 - direct_path_idx2_2) / acousticScenario.fs\n",
    "\n",
    " print(f\"Ground truth TDOA of source 2: {ground_truth_TDOA_2:.6f} seconds\")\n",
    "\n",
    " mic_signals, _, _, _, _ = create_micsigs(audio1_name, audio2_name, noise_name, acousticScenario)\n",
    "\n",
    " mic1 = mic_signals[:, 0] # Signal of the first mic\n",
    " mic2 = mic_signals[:, 1] # Signal of the second mic\n",
    "\n",
    " cross_corr = signal.correlate(mic1, mic2, mode=\"full\")\n",
    " lags = signal.correlation_lags(len(mic1), len(mic2), mode=\"full\")\n",
    "\n",
    " cross_corr /= np.max(np.abs(cross_corr))\n",
    " peaks, properties = signal.find_peaks(cross_corr, height=0.2) # Peaks above 50% of max\n",
    "\n",
    " if len(peaks) < 2:\n",
    "  raise ValueError(\"Less than 2 peaks found. Cannot estimate exactly 2 DOAs.\")\n",
    "\n",
    " # Select the two highest peaks\n",
    " peak_indices = np.argsort(properties[\"peak_heights\"])[-2:] # Get indices of top 2 peaks\n",
    " selected_peaks = peaks[peak_indices]\n",
    "\n",
    " TDOAestAll = []\n",
    "\n",
    " for peak in selected_peaks:\n",
    "    estimated_TDOA = lags[peak] / acousticScenario.fs\n",
    "    TDOAestAll.append(estimated_TDOA)\n",
    "\n",
    " estimated_TDOA = lags[np.argmax(cross_corr)] / acousticScenario.fs\n",
    "\n",
    " print(f\"First estimated TDOA: {TDOAestAll[1]:.6f} seconds\")\n",
    " print(f\"Second estimated TDOA: {TDOAestAll[0]:.6f} seconds\")\n",
    "\n",
    " c = 340 # Speed of sound in air (m/s)\n",
    " mic_distance = acousticScenario.distBwMics\n",
    " TDOAestAll = np.array(TDOAestAll)\n",
    " cos_theta = (TDOAestAll * c) / mic_distance # estimated cosine of the angle\n",
    " cos_theta = np.clip(cos_theta, -1, 1)\n",
    " DOA_estimate = np.arccos(cos_theta) * (180 / np.pi) # Angle in degrees\n",
    "\n",
    " print(f\"estimated DOA: {DOA_estimate[1]:.2f} degrees\")\n",
    " print(f\"estimated DOA: {DOA_estimate[0]:.2f} degrees\")\n",
    "\n",
    "TDOA_corr_2(\"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\whitenoise_signal_1.wav\", \"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\whitenoise_signal_2.wav\", \"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\Babble_noise1.wav\", acousticScenario, mic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 6\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def create_micsigs_2(rir_files, audio_file):\n",
    "  # \"\"\"Generates microphone signals from measured impulse responses.\"\"\"\n",
    "  rir_signals = [sf.read(f)[0] for f in rir_files]\n",
    "  audio, fs_audio = sf.read(audio_file)\n",
    "\n",
    "  # Ensure sampling rates match\n",
    "  fs_rir = sf.read(rir_files[0])[1]\n",
    "\n",
    "  T_ds = int(3*fs_rir)\n",
    "  audio = audio[0:T_ds]\n",
    "\n",
    "  if fs_audio != fs_rir:\n",
    "    audio = sig.resample(audio, int(len(audio) * fs_rir / fs_audio))\n",
    "\n",
    "  # Convolve with impulse response\n",
    "  mic_signals = [sig.fftconvolve(audio, rir)[:len(audio)] for rir in rir_signals]\n",
    "\n",
    "  return np.column_stack(mic_signals), fs_rir\n",
    "\n",
    "def estimate_tdoa(mic1, mic2, fs):\n",
    "  \"\"\"Estimates the time difference of arrival (TDOA) using cross-correlation.\"\"\"\n",
    "  # corr = sig.correlate(mic1, mic2, mode='full')\n",
    "  # delay = sig.correlation_lags(len(mic1),len(mic2), mode='full')\n",
    "  # tdoa = delay[np.argmax(corr)] / fs\n",
    "  corr = sig.correlate(mic1, mic2, mode='full')\n",
    "  delay = np.argmax(corr) - (len(mic1) - 1)\n",
    "  tdoa = delay / fs\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(corr)\n",
    "  plt.title(f\"Cross-Correlation (Delay={delay} samples, TDOA={tdoa:.6f} s)\")\n",
    "  plt.show()\n",
    "\n",
    "  return tdoa\n",
    "\n",
    "def estimate_doa(tdoa, mic_spacing, c=340):\n",
    "  \"\"\"Converts TDOA into a DOA estimate.\"\"\"\n",
    "  # theta = np.arccos((tdoa * c) / mic_spacing) * (180 / np.pi)\n",
    "  cos_theta = (tdoa * c) / mic_spacing\n",
    "  cos_theta = np.clip(cos_theta, -1, 1)\n",
    "  theta = np.arccos(cos_theta)*(180/np.pi)\n",
    "  return theta\n",
    "\n",
    "# Paths to impulse responses and target audio\n",
    "rir_path = \"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\head_mounted_rirs\\s30\"\n",
    "audio_file = \"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\part1_track1_dry.wav\"\n",
    "mic_pairs = [(\"HMIR_L1.wav\", \"HMIR_L2.wav\"), (\"HMIR_R1.wav\", \"HMIR_R2.wav\"), (\"HMIR_L1.wav\", \"HMIR_R1.wav\")]\n",
    "\n",
    "# Process each microphone pair\n",
    "for mic1_file, mic2_file in mic_pairs:\n",
    "  mic_files = [os.path.join(rir_path, mic1_file), os.path.join(rir_path, mic2_file)]\n",
    "  mic_signals, fs = create_micsigs_2(mic_files, audio_file)\n",
    "\n",
    "  # Estimate TDOA\n",
    "  tdoa = estimate_tdoa(mic_signals[:, 0], mic_signals[:, 1], fs)\n",
    "\n",
    "  # Define microphone spacing (1.3 cm for same ear, 21.5 cm for opposite ears)\n",
    "  # mic_spacing = 0.013 if \"L1\" in mic1_file and \"L2\" in mic2_file else 0.215\n",
    "  mic_spacing = 0.215 if \"L1\" in mic1_file and \"R1\" in mic2_file else 0.013\n",
    "\n",
    "  # Estimate DOA\n",
    "  doa = estimate_doa(tdoa, mic_spacing)\n",
    "  print(f\"DOA estimate for {mic1_file} & {mic2_file}: {doa:.2f}°\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIR_audio1, RIR_audio2 = np.dsplit(acousticScenario.RIRsAudio, 2)\n",
    "# RIR_audio1 = RIR_audio1.squeeze(axis=2)\n",
    "# RIR_audio2 = RIR_audio2.squeeze(axis=2)\n",
    "# RIR1_audio1, RIR2_audio1, RIR3_audio1 = np.hsplit(RIR_audio1, 3)\n",
    "# RIR1_audio = acousticScenario.RIRsAudio[:,0,0]\n",
    "# RIR1_audio = RIR_audio1[:,0]\n",
    "# print(RIR1_audio.shape)\n",
    "\n",
    "    # rec_speech1 = scipy.signal.fftconvolve(speech1, RIR1_audio1)\n",
    "    # rec_speech2 = scipy.signal.fftconvolve(speech1, RIR2_audio1)\n",
    "    # rec_speech3 = scipy.signal.fftconvolve(speech1, RIR3_audio1)\n",
    "\n",
    "# rec_noise1 = scipy.signal.fftconvolve(noise1, RIR1_noise)\n",
    "# rec_noise2 = scipy.signal.fftconvolve(noise1, RIR2_noise)\n",
    "# rec_noise3 = scipy.signal.fftconvolve(noise1, RIR3_noise)\n",
    "\n",
    "# rec_speech1 = rec_speech1 + rec_noise1[0:len(rec_speech1)]\n",
    "# rec_speech2 = rec_speech2 + rec_noise2[0:len(rec_speech2)]\n",
    "# rec_speech3 = rec_speech3 + rec_noise3[0:len(rec_speech3)]\n",
    "\n",
    "# mic = np.column_stack((rec_speech1, rec_speech2, rec_speech3))\n",
    "\n",
    "    # RIR_noise1 = np.dsplit(acousticScenario.RIRsNoise, 2)\n",
    "    # RIR_noise1 = RIR_audio1.squeeze(axis=2)\n",
    "\n",
    "    # RIR1_audio1, RIR2_audio1, RIR3_audio1 = np.hsplit(RIR_audio1, 3)\n",
    "\n",
    "    # RIR1_noise = acousticScenario.RIRsNoise[:,0,0]\n",
    "    # RIR2_noise = acousticScenario.RIRsNoise[:,1,0]\n",
    "    # RIR3_noise = acousticScenario.RIRsNoise[:,2,0]\n",
    "\n",
    "    # max_cols = max(mic1.shape[1], mic2.shape[1])\n",
    "    # mic1_padded = np.pad(mic1, ((0, 0), (0, max_cols - mic1.shape[1])), mode='constant')\n",
    "    # mic2_padded = np.pad(mic2, ((0, 0), (0, max_cols - mic2.shape[1])), mode='constant')\n",
    "\n",
    "    # mic = np.vstack((mic1_padded,mic2_padded))\n",
    "    # mic = mic1_padded + mic2_padded\n",
    "\n",
    "# rec_signal1_tmp = rec_signal1_tmp + rec_noise_tmp[0:len(rec_signal1_tmp)]  #may have problems if length of noise is shorter than the signals!\n",
    "\n",
    "  # estimated_TDOA = lags[np.argmax(cross_corr)] / acousticScenario.fs\n",
    "\n",
    "  # fs = acousticScenario.fs # Sampling frequentie uit RIR GUI\n",
    "  # estimated_TDOA = lags[np.argmax(cross_corr)] / fs # TDOA in seconds\n",
    "\n",
    "  # print(f\"estimated TDOA: {estimated_TDOA:.6f} seconds\")\n",
    "\n",
    "  # cos_theta = (estimated_TDOA * c) / mic_distance # estimated cosine of the angle\n",
    "\n",
    "  # DOA_estimate = 90 - DOA_estimate # 90° is broadside, 180° is end-fire\n",
    "\n",
    "# print(f\"estimated DOA: {DOA_estimate[1]:.2f} degrees\")\n",
    "\n",
    "# mic_part6, fs_part6= create_micsigs_2(rir_path, audio_file)\n",
    "\n",
    "# print(mic_part6.shape)\n",
    "# sd.play(mic_signals[:,0], fs)\n",
    "\n",
    "  # if os.path.isdir(rir_path):\n",
    "  #       rir_files = glob.glob(os.path.join(rir_path, \"*.wav\"))  # 默认寻找 WAV 文件\n",
    "  #       if len(rir_files) == 0:\n",
    "  #           raise ValueError(f\"No RIR files found in {rir_path}\")\n",
    "  # else:\n",
    "  #       rir_files = rir_path  # 如果已经是列表，则直接使用\n",
    "\n",
    "  # # 读取所有 RIR 文件\n",
    "  # rir_signals = [sf.read(f)[0] for f in rir_files]\n",
    "\n",
    "#  rir1_1 = acousticScenario.RIRsAudio[:,0,0]\n",
    "#  rir2_2 = acousticScenario.RIRsAudio[:,1,0]\n",
    "\n",
    "#  rir1_2 = acousticScenario.RIRsAudio[:,0,1]\n",
    "#  rir2_2 = acousticScenario.RIRsAudio[:,1,1]\n",
    "\n",
    "#  mic1 = mic_signals[:, mic[0]] # Signal of the first mic\n",
    "#  mic2 = mic_signals[:, mic[1]] # Signal of the second mic\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal processing - Week 2: MUSIC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "winLength = 1024 # Window length\n",
    "nSources = acousticScenario.RIRsAudio.shape[-1] +\\\n",
    "    acousticScenario.RIRsNoise.shape[-1] # Number of sources\n",
    "theta = np.arange(0, np.pi, step=np.pi / 360)  # angles to consider\n",
    "\n",
    "print('Computing DOAs via freq.-domain MUSIC algorithm...')\n",
    "\n",
    "DOAestAll = DOA_corr(\"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\whitenoise_signal_1.wav\", \"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\whitenoise_signal_2.wav\", \"F:\\KU Leuven\\courses\\P&D ISSP\\project\\panddissp-base-main\\sound_files\\Babble_noise1.wav\", acousticScenario)\n",
    "# DOAestAll = np.zeros(nSources)  # default\n",
    "\n",
    "print(f'All estimated DOAs: {DOAestAll * 180 / np.pi}')\n",
    "\n",
    "# ------------------ DOA estimation performance check ------------------\n",
    "# Automatic selection of the target DOA\n",
    "DOAest, groundTruthDOAtalkers = genfcns.auto_choice_doa(\n",
    "    DOAestAll, acousticScenario\n",
    ")\n",
    "print(f'Selected estimated DOAs: {np.round(DOAest * 180 / np.pi, 2)}')\n",
    "print(f'Ground truth DOAs: {np.round(groundTruthDOAtalkers * 180 / np.pi, 2)}')\n",
    "# Check validity\n",
    "genfcns.check_plot_tdoas(DOAest, DOAestAll, acousticScenario)\n",
    "# print(f'Estimate error(s): {np.round((DOAest - groundTruthDOAtalkers) * 180/np.pi, 2)} deg.')\n",
    "print(f'Estimate error(s): {DOAestAll - np.round(groundTruthDOAtalkers * 180 / np.pi, 2)} deg.')\n",
    "print(DOAestAll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panddbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
